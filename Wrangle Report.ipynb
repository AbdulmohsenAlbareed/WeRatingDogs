{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "460a2e12",
   "metadata": {},
   "source": [
    "# Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d84c92",
   "metadata": {},
   "source": [
    "<hr style=\"border: 0.5px solid black\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9b1ca",
   "metadata": {},
   "source": [
    "### Intoduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e171096c",
   "metadata": {},
   "source": [
    "In this project, our goal is to apply the knowledge that we gained from Chapter \"Wrangle and Analyze Data\" to a real-world dataset. The dataset that we used in this project is WeRateDogs, which was collected from tweets in @dog_rates on Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27084ad",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c92469",
   "metadata": {},
   "source": [
    "We imported many libraries that help us for dealing with data.\n",
    "\n",
    "1.pandas \n",
    "\n",
    "2.numpy\n",
    "\n",
    "3.requests\n",
    "\n",
    "4.tweepy\n",
    "\n",
    "5.matplotlib.pyplot\n",
    "\n",
    "6.re\n",
    "\n",
    "7.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4715b31",
   "metadata": {},
   "source": [
    "<hr style=\"border: 0.5px solid black\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b95c2",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3254927b",
   "metadata": {},
   "source": [
    "In our project, we gathered data from three different sources for our analysis.\n",
    "\n",
    "1.Enhanced Twitter archive:  in  twitter_archive_enhanced.csv file.\n",
    "\n",
    "2.Image prediction data: obtained by online scraping.\n",
    "\n",
    "\n",
    "3.Twitter API: This dataset was downloaded from Twitter's API and converted from JSON to CSV.\n",
    "\n",
    "**Note:** In Twitter API i tried to gather the data from API but I faced error,so I used the data that already gathered on Udacity website (the error mentioned in wrangle_act.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe3951",
   "metadata": {},
   "source": [
    "<hr style=\"border: 0.5px solid black\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925699f0",
   "metadata": {},
   "source": [
    "### Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838da6b",
   "metadata": {},
   "source": [
    "In Assessing Data procces we diveded the issues into two type: Quality,Tidiness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf528d",
   "metadata": {},
   "source": [
    ">Quality Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ce00b",
   "metadata": {},
   "source": [
    "1.timestamp stored as string not date and added by '+0000'\n",
    "\n",
    "2.We need the original rating not retweets and replies (need to remove all the following columns:in_reply_to_status_id,in_reply_to_uesr_id,retweeted_status_id,retweeted_user_id,retweeted_status_timestamp )\n",
    "\n",
    "3.The source column is not readable,We can remove the html tags to be easy to read the source of the tweet\n",
    "\n",
    "4.There is some rows that have rating_numerator with large numbers (e.g. In row 2074 the rating_numerator is 420 out of 10 !!)\n",
    "\n",
    "5.There is some rows that have rating_denominator grater than 10\n",
    "\n",
    "6.After drop the rows that have rating_denominator!=10,We can drop column rating_denominator and rename the column rating_numerator to \"rating_dog\".We now the rating is out of 10 Now.\n",
    "\n",
    "7.rename 'timestamp' to 'tweet_timestamp'\n",
    "\n",
    "8.rename 'text' ot 'tweet_text'\n",
    "\n",
    "9.Some of the tweets that the img_prdc classifies as images of dogs are not dogs, so based on that, we will remove the tweets that are not dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2b80c",
   "metadata": {},
   "source": [
    ">Tidiness issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc39e5",
   "metadata": {},
   "source": [
    "1.The doggo,floofer,pupper and puppo can be in one columns called \"dog_stage\"\n",
    "\n",
    "2.There are Three tables: tweets_arhv,img_pdct and tweet_json. We need to merge all of these tables together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c70f2",
   "metadata": {},
   "source": [
    "<hr style=\"border: 0.5px solid black\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33561c8",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0446b846",
   "metadata": {},
   "source": [
    "In this section, we solve all the issues we mentioned above by using Pandas. We dropped the columns that we didn't need. Also, remove rows that do not comply with our requirements. Addintional merged all three tables with each other and stored them in a file named \"twitter_archive_master' in csv format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
